{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "af0c3b9d-103c-4d16-bfe3-9882c7ef543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 24.0 from /Users/kerekmen/miniconda3/envs/s4/lib/python3.12/site-packages/pip (python 3.12)\n",
      "['/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/opt/homebrew/Cellar/python@3.12/3.12.3/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/opt/homebrew/Cellar/jupyterlab/4.1.6_1/libexec/lib/python3.12/site-packages', '/opt/homebrew/opt/z3/lib/python3.12/site-packages', '/opt/homebrew/opt/llvm/lib/python3.12/site-packages', '/opt/homebrew/opt/certifi/lib/python3.12/site-packages', '/opt/homebrew/opt/z3/lib/python3.12/site-packages', '/opt/homebrew/opt/llvm/lib/python3.12/site-packages', '/opt/homebrew/lib/python3.12/site-packages', '/Users/kerekmen/miniconda3/envs/s4/lib/python3.12/site-packages', '/Users/kerekmen/miniconda3/envs/s4/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "!pip --version\n",
    "import sys\n",
    "sys.path.append(\"/Users/kerekmen/miniconda3/envs/s4/lib/python3.12/site-packages\")\n",
    "print(sys.path)\n",
    "\n",
    "import torch\n",
    "torch.random.manual_seed(0)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5bf5bbd9-19dc-47f1-822c-597576f10694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_SSM(N):\n",
    "    A = torch.randn(N, N)\n",
    "    B = torch.randn(N, 1)\n",
    "    C = torch.randn(1, N)\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dd0ed53a-071d-4852-b916-4efc7f70403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(A, B, C, step):\n",
    "    I = np.eye(A.shape[0])\n",
    "    BL = torch.linalg.inv(torch.tensor(I - (step / 2.0) * A))\n",
    "    Ab = BL @ (I + (step / 2.0) * A)\n",
    "    Bb = (BL * step) @ B\n",
    "    return Ab, Bb, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e377a25a-6bcc-4b6a-a065-db427bafa1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_SSM(Ab, Bb, Cb, u, x0):\n",
    "    \"\"\"\n",
    "    Simulate the state-space model using a for-loop to replicate JAX lax.scan functionality.\n",
    "\n",
    "    Parameters:\n",
    "    - Ab (torch.Tensor): The state transition matrix.\n",
    "    - Bb (torch.Tensor): The input matrix.\n",
    "    - Cb (torch.Tensor): The output matrix.\n",
    "    - u (torch.Tensor): The input sequence (time steps, input_dim).\n",
    "    - x0 (torch.Tensor): The initial state.\n",
    "\n",
    "    Returns:\n",
    "    - x_out (torch.Tensor): Sequence of states.\n",
    "    - y_out (torch.Tensor): Sequence of outputs.\n",
    "    \"\"\"\n",
    "    Ab = torch.tensor(Ab)\n",
    "    Bb = torch.tensor(Bb)\n",
    "    Cb = torch.tensor(Cb)\n",
    "    \n",
    "    \n",
    "    def step(x_k_1, u_k):\n",
    "        x_k_1 = torch.tensor(x_k_1)\n",
    "        u_k = torch.tensor(u_k)\n",
    "        \n",
    "        x_k = Ab @ x_k_1 + Bb @ u_k\n",
    "        y_k = Cb @ x_k\n",
    "        return x_k, y_k\n",
    "\n",
    "    x_out = [x0]\n",
    "    y_out = []\n",
    "\n",
    "    x_k = x0\n",
    "    for u_k in u:\n",
    "        x_k, y_k = step(x_k, u_k)\n",
    "        x_out.append(x_k)\n",
    "        y_out.append(y_k)\n",
    "\n",
    "    return torch.stack(x_out[1:]), torch.stack(y_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c969744a-ca01-41d2-a7d2-8a06febab270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_SSM(A, B, C, u):\n",
    "    L = u.shape[0]\n",
    "    N = A.shape[0]\n",
    "    Ab, Bb, Cb = discretize(A, B, C, step=1.0 / L)\n",
    "    # Run recurrence\n",
    "    return scan_SSM(Ab, Bb, Cb, u[:, np.newaxis], np.zeros(N,))[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d53413-4d01-43e4-9fcc-a1a52a6885a3",
   "metadata": {},
   "source": [
    "# example of calculting ode in mechanics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8af9dfe4-ed08-42c6-8282-f0f067db4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_force(t):\n",
    "    x = np.sin(10 * t)\n",
    "    return x * (x > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7f85ad4b-2149-43b2-9c36-31e5f5809e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_mass(k, b, m):\n",
    "    A = np.array([[0, 1], [-k / m, -b / m]])\n",
    "    B = np.array([[0], [1.0 / m]])\n",
    "    C = np.array([[1.0, 0]])\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba1b86f3-ce8a-451c-9ac9-90ac4769c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_ssm():\n",
    "    # SSM\n",
    "    ssm = example_mass(k=40, b=5, m=1)\n",
    "\n",
    "    # L samples of u(t).\n",
    "    L = 100\n",
    "    step = 1.0 / L\n",
    "    ks = np.arange(L)\n",
    "    u = example_force(ks * step)\n",
    "\n",
    "    # Approximation of y(t).\n",
    "    y = run_SSM(*ssm, u)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fea6b49f-cd39-4184-90eb-f55e81687e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/ff779wh56ndbtlz869wwf1tr0000gn/T/ipykernel_81326/2295215111.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Ab = torch.tensor(Ab)\n",
      "/var/folders/k1/ff779wh56ndbtlz869wwf1tr0000gn/T/ipykernel_81326/2295215111.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Bb = torch.tensor(Bb)\n",
      "/var/folders/k1/ff779wh56ndbtlz869wwf1tr0000gn/T/ipykernel_81326/2295215111.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_k_1 = torch.tensor(x_k_1)\n"
     ]
    }
   ],
   "source": [
    "example_ssm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd98cd2-58f2-4f76-88b4-c754cd8bf2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "040a18a9-1474-4b3e-87e8-7e7f4b347798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.pad(np.arange(10), (0, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8e636421-4d50-44e1-8de9-ebea5f9857c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(10,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d2d2de63-7364-4146-8d82-e9f7a6845aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5966,  0.1820, -0.8567,  1.1006, -1.0712,  0.1227, -0.5663,  0.3731,\n",
       "        -0.8920, -1.5091])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3e6a704e-a009-4868-bdf3-e88f0b4e9461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded input shape: torch.Size([1, 1, 16])\n",
      "Output shape: torch.Size([1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Dummy input tensor of shape [16]\n",
    "input_tensor = torch.randn(16)\n",
    "\n",
    "# Expand to [1, 1, 16] for convolution\n",
    "expanded_input = input_tensor.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "print(f'Expanded input shape: {expanded_input.shape}')  # Should be [1, 1, 16]\n",
    "\n",
    "# Define a convolution layer with the kernel of size (16, 1, 1)\n",
    "conv_layer = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=16)\n",
    "\n",
    "# Apply convolution\n",
    "output = conv_layer(expanded_input)\n",
    "\n",
    "print(f'Output shape: {output.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "1a0c9bc8-84f1-4a29-9838-c6ad4046b4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(16).view(4, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "94fcfcff-62bb-4084-83cc-1c6c3abcceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.1991, -0.0257,  1.8024],\n",
       "        [ 0.0000,  0.0000, -0.5687, -0.4755],\n",
       "        [ 0.0000,  0.0000,  0.0000,  1.2937],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.triu(1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "35e13a89-e4e7-49da-b51d-ff9dac40558a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -1.1991, -0.0257,  1.8024],\n",
       "        [ 1.1991,  0.0000, -0.5687, -0.4755],\n",
       "        [ 0.0257,  0.5687,  0.0000,  1.2937],\n",
       "        [-1.8024,  0.4755, -1.2937,  0.0000]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a - a.transpose(-1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9bbc7ac3-ce9e-46af-aa2e-2d7adc0bf302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5583, 0.4664])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot                            # [D], [D] -> []\n",
    "batched_dot = torch.vmap(torch.dot, in_dims=0)  # [N, D], [N, D] -> [N]\n",
    "x, y = torch.randn(2, 5), torch.randn(2, 5)\n",
    "batched_dot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "504284ed-de4d-459a-984f-3e34229ac3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5583)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].dot(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "abb7fd5f-0bb0-4516-afd8-27eee82a2777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4664)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].dot(y[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "10939a73-2c28-439e-b00a-135384ccd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.Linear(10, 1)\n",
    "linear_new = torch.vmap(layer, in_dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4898023e-6cdb-45db-b4fd-b7fcb55cf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_old = nn.ModuleList([layer for i in range(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "71d46caa-a09b-422c-8352-05dd543a9720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.4168],\n",
       "         [ 0.5909],\n",
       "         [-0.6702],\n",
       "         [ 0.8237],\n",
       "         [-0.0082]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.4168],\n",
       "         [ 0.5909],\n",
       "         [-0.6702],\n",
       "         [ 0.8237],\n",
       "         [-0.0082]], grad_fn=<AddmmBackward0>)]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(5, 10)\n",
    "\n",
    "x = []\n",
    "for lin in linear_old:\n",
    "    x.append(lin(input))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e3f8e097-ea0f-4118-9a20-41ac9317cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4168],\n",
       "        [ 0.5909],\n",
       "        [-0.6702],\n",
       "        [ 0.8237],\n",
       "        [-0.0082]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_new(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "6a0ab5bc-eb11-4321-97df-67943d0ceb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9]],\n",
       "\n",
       "        [[10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.arange(20).view(2, 2, 5) # B x Samples x features\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0553f630-b625-4c5f-b0b3-21d9deae3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list()\n",
    "for i in input:\n",
    "    x.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "58d087c4-0e99-4b79-9b90-8c6b1da8e3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 3])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9d02a499-4740-4c9e-91c9-4e44cc816f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 35],\n",
       "        [60, 85]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(input, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6618c969-ca05-406b-84ff-6af67200328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_look_ahead_mask(size):\n",
    "    # old: mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)\n",
    "    # new from: https://discuss.pytorch.org/t/attn-mask-in-nn-multiheadattention/173603/3\n",
    "    # seems like we got the attention mask wrong, it should be -inf for the future tokens\n",
    "    # so we need to set the diagonal to 0 and the upper triangle to -inf\n",
    "    arr = [[-np.inf for _ in range(size)] for _ in range(size)]\n",
    "    arr = torch.tensor(arr)\n",
    "    mask = torch.triu(arr, diagonal=1)\n",
    "    return mask\n",
    "\n",
    "mask = generate_look_ahead_mask(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "985be09b-2a8a-42e0-8d85-1cf4ffb055d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(mask, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "97f6047b-0a5d-4680-bc0a-da55ee37544e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "49ad4aca-f476-48b5-bc48-3811d5e1a58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.tensor([13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
    "         1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
    "         1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
    "        83,  1, 46, 82, 15,  1, 40, 65, 82, 82]) \n",
    "\n",
    "tgt = torch.tensor([ 3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,  1,\n",
    "        70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,  1,\n",
    "        34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87, 83,\n",
    "         1, 46, 82, 15,  1, 40, 65, 82, 82, 73])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "50a1a934-b8ed-4817-8dd9-22cefdffa4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "         1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
       "         1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
       "        83,  1, 46, 82, 15,  1, 40, 65, 82, 82, 73])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((src, tgt[-1:None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "58bdabed-b444-4b7d-90aa-4d44ee47c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.tensor(np.array([(src, tgt), (src, tgt)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "26400f0a-7f6d-4646-ad93-0dc509354b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "          1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
       "          1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
       "         83,  1, 46, 82, 15,  1, 40, 65, 82, 82, 73],\n",
       "        [13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "          1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
       "          1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
       "         83,  1, 46, 82, 15,  1, 40, 65, 82, 82, 73]])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((m[:, 0, :], m[:, 1, -1:None]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "66279ccc-39ad-46c1-9736-8b44c5bccd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "          1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
       "          1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
       "         83,  1, 46, 82, 15,  1, 40, 65, 82, 82],\n",
       "        [13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "          1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80, 13,\n",
       "          1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72, 79, 87,\n",
       "         83,  1, 46, 82, 15,  1, 40, 65, 82, 82]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f2911582-3364-4937-b780-450d0db97475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82,\n",
       "          89,  1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73,\n",
       "          80, 13,  1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83,\n",
       "          72, 79, 87, 83,  1, 46, 82, 15,  1, 40, 65, 82, 82],\n",
       "         [ 3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "           1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80,\n",
       "          13,  1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72,\n",
       "          79, 87, 83,  1, 46, 82, 15,  1, 40, 65, 82, 82, 73]],\n",
       "\n",
       "        [[13,  3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82,\n",
       "          89,  1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73,\n",
       "          80, 13,  1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83,\n",
       "          72, 79, 87, 83,  1, 46, 82, 15,  1, 40, 65, 82, 82],\n",
       "         [ 3, 34, 84,  1, 70, 85, 68, 71, 69,  1, 70, 65, 67, 84, 79, 82, 89,\n",
       "           1, 70, 79, 82,  1, 65,  1, 70, 73, 69, 76, 68,  1, 84, 82, 73, 80,\n",
       "          13,  1, 34,  1, 84, 79, 85, 82,  1, 71, 85, 73, 68, 69,  1, 83, 72,\n",
       "          79, 87, 83,  1, 46, 82, 15,  1, 40, 65, 82, 82, 73]]])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748e16c-f029-4e85-853f-31b6d6653480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
